{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from keras.layers import *\n",
    "from keras import Sequential\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.optimizers import Adam\n",
    "from keras.engine.topology import Layer\n",
    "from keras import initializers, regularizers, constraints\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "tqdm.pandas()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = pd.read_json('./train.json')\n",
    "TEST_DF = pd.read_json('./test.json')\n",
    "\n",
    "X_train = TRAIN_DF['audio_embedding'].tolist()\n",
    "X_test = TEST_DF['audio_embedding'].tolist()\n",
    "y_train = TRAIN_DF['is_turkey'].values\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=10) \n",
    "X_test = pad_sequences(X_test, maxlen=10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>is_turkey</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "      <th>vid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...</td>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>kDCk3hLIVXo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>DPcGzqHoo7Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>230</td>\n",
       "      <td>7yM63MTHh5k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...</td>\n",
       "      <td>520</td>\n",
       "      <td>1</td>\n",
       "      <td>510</td>\n",
       "      <td>luG3RmUAxxM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PIm3cjxTpOk</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  \\\n",
       "0  [[172, 34, 216, 110, 208, 46, 95, 66, 161, 125...   \n",
       "1  [[169, 20, 165, 102, 205, 62, 110, 103, 211, 1...   \n",
       "2  [[148, 8, 138, 60, 237, 48, 121, 108, 145, 177...   \n",
       "3  [[151, 0, 162, 88, 171, 71, 47, 90, 179, 190, ...   \n",
       "4  [[162, 17, 187, 111, 211, 105, 92, 67, 203, 15...   \n",
       "\n",
       "   end_time_seconds_youtube_clip  is_turkey  start_time_seconds_youtube_clip  \\\n",
       "0                             70          0                               60   \n",
       "1                             40          1                               30   \n",
       "2                            240          1                              230   \n",
       "3                            520          1                              510   \n",
       "4                             10          0                                0   \n",
       "\n",
       "        vid_id  \n",
       "0  kDCk3hLIVXo  \n",
       "1  DPcGzqHoo7Y  \n",
       "2  7yM63MTHh5k  \n",
       "3  luG3RmUAxxM  \n",
       "4  PIm3cjxTpOk  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_DF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio_embedding</th>\n",
       "      <th>end_time_seconds_youtube_clip</th>\n",
       "      <th>start_time_seconds_youtube_clip</th>\n",
       "      <th>vid_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>pyKh38FXD3E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>THhP1idrWXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>jsw3T6GY2Nw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...</td>\n",
       "      <td>24</td>\n",
       "      <td>14</td>\n",
       "      <td>nFkXTMHcjMU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>Au8g9kAlrLQ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     audio_embedding  \\\n",
       "0  [[177, 20, 226, 132, 198, 81, 111, 59, 132, 18...   \n",
       "1  [[169, 21, 204, 161, 195, 72, 60, 39, 152, 184...   \n",
       "2  [[165, 13, 198, 141, 199, 81, 173, 54, 119, 11...   \n",
       "3  [[167, 18, 188, 159, 198, 63, 156, 36, 179, 22...   \n",
       "4  [[178, 32, 181, 100, 198, 46, 82, 83, 136, 227...   \n",
       "\n",
       "   end_time_seconds_youtube_clip  start_time_seconds_youtube_clip       vid_id  \n",
       "0                             10                                0  pyKh38FXD3E  \n",
       "1                             40                               30  THhP1idrWXA  \n",
       "2                             40                               30  jsw3T6GY2Nw  \n",
       "3                             24                               14  nFkXTMHcjMU  \n",
       "4                             40                               30  Au8g9kAlrLQ  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEST_DF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Deep Learning Model Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/qqgeogor/keras-lstm-attention-glove840b-lb-0-043\n",
    "class Attention(Layer):\n",
    "    def __init__(self, step_dim,\n",
    "                 W_regularizer=None, b_regularizer=None,\n",
    "                 W_constraint=None, b_constraint=None,\n",
    "                 bias=True, **kwargs):\n",
    "        self.supports_masking = True\n",
    "        self.init = initializers.get('glorot_uniform')\n",
    "\n",
    "        self.W_regularizer = regularizers.get(W_regularizer)\n",
    "        self.b_regularizer = regularizers.get(b_regularizer)\n",
    "\n",
    "        self.W_constraint = constraints.get(W_constraint)\n",
    "        self.b_constraint = constraints.get(b_constraint)\n",
    "\n",
    "        self.bias = bias\n",
    "        self.step_dim = step_dim\n",
    "        self.features_dim = 0\n",
    "        super(Attention, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        assert len(input_shape) == 3\n",
    "\n",
    "        self.W = self.add_weight((input_shape[-1],),\n",
    "                                 initializer=self.init,\n",
    "                                 name='{}_W'.format(self.name),\n",
    "                                 regularizer=self.W_regularizer,\n",
    "                                 constraint=self.W_constraint)\n",
    "        self.features_dim = input_shape[-1]\n",
    "\n",
    "        if self.bias:\n",
    "            self.b = self.add_weight((input_shape[1],),\n",
    "                                     initializer='zero',\n",
    "                                     name='{}_b'.format(self.name),\n",
    "                                     regularizer=self.b_regularizer,\n",
    "                                     constraint=self.b_constraint)\n",
    "        else:\n",
    "            self.b = None\n",
    "\n",
    "        self.built = True\n",
    "\n",
    "    def compute_mask(self, input, input_mask=None):\n",
    "        return None\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        features_dim = self.features_dim\n",
    "        step_dim = self.step_dim\n",
    "\n",
    "        eij = K.reshape(K.dot(K.reshape(x, (-1, features_dim)),\n",
    "                        K.reshape(self.W, (features_dim, 1))), (-1, step_dim))\n",
    "\n",
    "        if self.bias:\n",
    "            eij += self.b\n",
    "\n",
    "        eij = K.tanh(eij)\n",
    "\n",
    "        a = K.exp(eij)\n",
    "\n",
    "        if mask is not None:\n",
    "            a *= K.cast(mask, K.floatx())\n",
    "\n",
    "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
    "\n",
    "        a = K.expand_dims(a)\n",
    "        weighted_input = x * a\n",
    "        return K.sum(weighted_input, axis=1)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return input_shape[0],  self.features_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# define roc_callback, inspired by https://github.com/keras-team/keras/issues/6050#issuecomment-329996505\n",
    "def auc_roc(y_true, y_pred):\n",
    "    # any tensorflow metric\n",
    "    value, update_op = tf.metrics.auc(y_true, y_pred)\n",
    "\n",
    "    # find all variables created for this metric\n",
    "    metric_vars = [i for i in tf.local_variables() if 'auc_roc' in i.name.split('/')[1]]\n",
    "\n",
    "    # Add metric variables to GLOBAL_VARIABLES collection.\n",
    "    # They will be initialized for new session.\n",
    "    for v in metric_vars:\n",
    "        tf.add_to_collection(tf.GraphKeys.GLOBAL_VARIABLES, v)\n",
    "\n",
    "    # force to update metric values\n",
    "    with tf.control_dependencies([update_op]):\n",
    "        value = tf.identity(value)\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(learn_rate=0.01, momentum=0.8, dropout_rate1=0.1, dropout_rate2=0.0, neurons=128):\n",
    "    model = Sequential()\n",
    "    model.add(BatchNormalization(momentum=momentum,input_shape=(10, 128)))\n",
    "    model.add(Bidirectional(GRU(neurons, dropout=dropout_rate1, recurrent_dropout=dropout_rate2, activation='relu', return_sequences=True)))\n",
    "    model.add(Attention(10))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=learn_rate), metrics=[auc_roc])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X_train, y_train, X_test, n_splits=5, verbose=2):\n",
    "\n",
    "    missfits = [] ## missclassified items\n",
    "    kf = KFold(n_splits=n_splits, shuffle=True, random_state=424242)\n",
    "    preds = []\n",
    "    historys = []\n",
    "    fold = 0\n",
    "    aucs = 0.0\n",
    "    threshold = 0.5\n",
    "\n",
    "    for train_idx, val_idx in kf.split(X_train):\n",
    "        x_train_f = X_train[train_idx]\n",
    "        y_train_f = y_train[train_idx]\n",
    "        x_val_f = X_train[val_idx]\n",
    "        y_val_f = y_train[val_idx]\n",
    "\n",
    "        model = get_model(neurons=128, momentum=0.6, learn_rate=0.001, dropout_rate2=0.1, dropout_rate1=0.1)\n",
    "        history = model.fit(x_train_f, y_train_f,\n",
    "            batch_size=128,\n",
    "            epochs=20,\n",
    "            verbose = verbose,\n",
    "            validation_data=(x_val_f, y_val_f),\n",
    "            callbacks = [])\n",
    "        \n",
    "        preds_val = model.predict([x_val_f], batch_size=512)\n",
    "\n",
    "        \n",
    "        preds_test = model.predict(X_test)\n",
    "        preds.append(preds_test)\n",
    "        \n",
    "        historys.append(history)\n",
    "        \n",
    "        score = roc_auc_score(y_val_f, preds_val)\n",
    "        aucs += score\n",
    "    \n",
    "        preds_val = preds_val > threshold\n",
    "        for idx in range(len(x_val_f)):\n",
    "            if preds_val[0][0] != y_val_f[idx]:\n",
    "                missfits.append(TRAIN_DF.values[train_idx[idx]])\n",
    "    \n",
    "        fold+=1\n",
    "    \n",
    "        print('Fold {}, AUC = {}'.format(fold, score))\n",
    "    \n",
    "    preds = np.asarray(preds)[...,0]\n",
    "    preds = np.mean(preds, axis=0)\n",
    "    print(\"Cross Validation AUC = {}\".format(aucs/n_splits))\n",
    "    \n",
    "    return (preds, historys, missfits)\n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1, AUC = 0.9855699855699855\n",
      "Fold 2, AUC = 0.9850862312694374\n",
      "Fold 3, AUC = 0.9835907335907337\n",
      "Fold 4, AUC = 0.9936837519965152\n",
      "Fold 5, AUC = 0.9913315850815851\n",
      "Cross Validation AUC = 0.9878524575016513\n"
     ]
    }
   ],
   "source": [
    "preds, historys, missfits = train_model(X_train, y_train, X_test, n_splits=5, verbose=0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Not so bad for a Baseline but not enough ;p "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "?pd.DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting more data from external sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "! mkdir -p html/train/0\n",
    "! mkdir -p html/train/1\n",
    "! mkdir -p html/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://www.youtube.com/watch?v=\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid_ids_train_0 = TRAIN_DF[TRAIN_DF.is_turkey==0]['vid_id'].values\n",
    "vid_ids_train_1 = TRAIN_DF[TRAIN_DF.is_turkey==1]['vid_id'].values\n",
    "vid_ids_test = TEST_DF['vid_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "704\n",
      "491\n",
      "1196\n"
     ]
    }
   ],
   "source": [
    "print(len(vid_ids_train_0))\n",
    "print(len(vid_ids_train_1))\n",
    "print(len(vid_ids_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 704/704 [06:31<00:00,  1.69it/s]\n"
     ]
    }
   ],
   "source": [
    "prefix = \"./html/train/0/\"\n",
    "for vid_id in tqdm(vid_ids_train_0):\n",
    "    url = BASE_URL + vid_id\n",
    "    output_file = prefix + vid_id + \".html\"\n",
    "    !wget '{url}' -o '{output_file}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 316/491 [03:00<01:33,  1.86it/s]"
     ]
    }
   ],
   "source": [
    "prefix = \"./html/train/1/\"\n",
    "for vid_id in tqdm(vid_ids_train_1):\n",
    "    url = BASE_URL + vid_id\n",
    "    output_file = prefix + vid_id + \".html\"\n",
    "    !wget '{url}' -o '{output_file}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = \"./html/test/\"\n",
    "for vid_id in tqdm(vid_ids_test):\n",
    "    url = BASE_URL + vid_id\n",
    "    output_file = prefix + vid_id + \".html\"\n",
    "    !wget '{url}' -o '{output_file}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''        \n",
    "        for idx, p in enumerate(preds_val):\n",
    "            unicorn = unicornify(train.loc[val_idx[idx]])\n",
    "            if unicorn:\n",
    "                preds_val[idx][0] = unicorn\n",
    " '''       \n",
    "    \n",
    "    \n",
    "'''    \n",
    "    voyanteries = model.predict(x_test)\n",
    "    preds.append(voyanteries)\n",
    "    for idx, p in enumerate(voyanteries):\n",
    "        unicorn = unicornify(test.loc[idx])\n",
    "        print(unicorn)\n",
    "        if unicorn:\n",
    "            voyanteries[idx][0] = unicorn\n",
    "'''    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
